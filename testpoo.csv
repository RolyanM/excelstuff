name	ring	quadrant	isNew	description
Applying product management to internal platforms	Fart	Poo	FALSE	<p>We keep getting good feedback from teams <strong>applying product management to internal platforms</strong>. One key feature to remember, though: It's not just about team structure or renaming existing platform teams; it’s also about applying product-centric working practices within the team. Specifically, we've received feedback that teams face challenges with this technique unless they have a product-centric mindset. This likely means additional roles, such as a product manager, alongside changes to other areas, such as requirements gathering and the measurement of success. Working this way means establishing empathy with internal consumers (the development teams) and collaborating with them on the design. Platform product managers create roadmaps and ensure the platform delivers value to the business and enhances the developer experience. We continue to see this technique as key to building internal platforms to roll out new digital solutions quickly and efficiently.</p>
CI/CD infrastructure as a service	Fart	Poo	TRUE	<p>The options for <strong>CI/CD infrastructure as a service</strong> have become so manifold and mature that the cases in which it's worth managing your entire CI infrastructure yourself are becoming very rare. Using managed services like <a href="/radar/platforms/github-actions">GitHub Actions</a>, <a href="/radar/platforms/azure-devops">Azure DevOps</a> or <a href="/radar/platforms/gitlab-ci-cd">Gitlab CI/CD</a> comes with all the common advantages (and trade-offs) of managed cloud services. You don't have to spend time, effort and hardware costs on maintenance and operations of this often complex infrastructure. Teams can take advantage of elasticity and self-service, whereas provisioning more of the right agents or getting a new plugin or feature are often a bottleneck in companies that host CI themselves. Even the use cases that require to run build and verification on your own hardware can now mostly be covered with self-hosted runners (we've written about some for GitHub Actions, <a href="/radar/platforms/actions-runner-controller">actions-runner-controller</a> and the <a href="/radar/tools/philips-s-self-hosted-github-runner">Philips's self-hosted GitHub runner</a>). Note, however, that you won’t get out-of-the-box security just because you are using a managed services; while mature services provide all the security features you need, you'll still need to use them to implement <a href="/radar/techniques/zero-trust-security-for-ci-cd">zero trust security for your CI/CD</a> infrastructure.</p>
Dependency pruning	Fart	Poo	TRUE	<p>Starter kits and templates are widely used in software projects to speed up initial setup, but they can pull in many unnecessary dependencies for a particular project. It's important to practice <strong>dependency pruning</strong> — periodically taking a hard look at these dependencies and pruning any that are not used. This helps reduce build and deploy times and decrease the project's attack surface by removing potential vulnerabilities. Although this isn't a new technique, given the increasing frequency of attacks on software supply chains, we advocate for renewed attention to it.</p>
Run cost as architecture fitness function	Fart	Poo	FALSE	"<p>Automatically estimating, tracking and predicting cloud infrastructure run cost is crucial for today's organizations. The cloud providers' savvy pricing models, combined with the proliferation of pricing parameters and the dynamic nature of today's architecture, can lead to surprisingly expensive run costs. Even though this technique has been in Adopt since 2019, we want to highlight the importance of considering <strong>run cost as an architecture fitness function</strong>, especially today, due to accelerated cloud adoption and the growing attention to FinOps practices. Many commercial platforms provide tools that can consolidate and clarify cloud costs for business leaders. Some of them are designed to show cloud run costs to finance organizations or originating business units. </p>

<p>However, cloud consumption decisions are usually made at the engineering level, where systems are designed. It's important that the engineers making design decisions have some way of predicting the cost impact of their architectural decisions. Some teams automate this prediction early in the development lifecycle. Tools like <a href=""/radar/tools/infracost"">Infracost</a> help teams predict cost impact when thinking about possible changes to infrastructure as code. This computation can be automated and woven into the CD pipeline. Note that cost will be impacted by architectural decisions combined with actual usage levels; to do this properly, you need good projections of expected usage levels. Early and frequent feedback on run cost can prevent it from soaring. When the predicted cost deviates from what was expected or acceptable, the team can discuss whether it's time to evolve the architecture.</p>"
Accessibility annotations in designs	Trial	Poo	TRUE	<p>The earlier accessibility is considered in software delivery, the easier and cheaper it is to ensure what's built works for as many people as possible. Tools that help communicate <strong>accessibility annotations in designs</strong> help teams consider important elements like document structure, semantic HTML and alternative texts from the beginning of their work. This enables them to ensure user interfaces meet global accessibility standards and address common failures that are actually fairly easy to avoid. <a href="/radar/tools/figma">Figma</a> offers a range of accessibility notation plugins: <a href="https://www.figma.com/community/file/953682768192596304">The A11y Annotation Kit</a>, Twitter's <a href="https://www.figma.com/community/file/976946194228458698">Accessibility Annotation Library</a> and the Axe toolset's <a href="https://www.figma.com/community/plugin/1085612091163821851/Axe-for-Designers-(FREE)">Axe for Designers</a>.</p>
Bounded low-code platforms	Trial	Poo	FALSE	"<p>We've always been advocates of writing less code. Simplicity is one of the core values underlying our sensible defaults for software development. For example, we try not to anticipate needs and only introduce code that satisfies immediate business requirements and nothing else. One way to achieve this is to create engineering platforms that make this possible on an organizational basis.</p>

<p>This is also the stated aim of many low-code platforms surging in popularity right now. Platforms like <a href=""https://www.mendix.com/"">Mendix</a> or <a href=""https://powerapps.microsoft.com/"">Microsoft Power Apps</a> can expose common business processes for reuse and simplify the problems of getting new functionality deployed and in the hands of users. These platforms have made great strides in recent years with testability and support for good engineering practices. They're particularly useful for simple tasks or event-triggered apps. However, asking them to adapt to a nearly infinite range of business requirements brings complexity. Although developers might be writing less (or zero) code, they must also become experts in an all-encompassing commercial platform. We would advise businesses to consider if they need all the functionality these products bring or if they're better off pursuing <strong>bounded low-code platforms</strong>, either by developing their own <a href=""/radar/techniques/applying-product-management-to-internal-platforms"">platform as an internal product</a> or by carefully constraining the use of commercial low-code products to those simple tasks at which they excel.</p>"
Demo frontends for API-only products	Trial	Poo	TRUE	<p>One of the big challenges in developing APIs is capturing and communicating their business value. APIs are, by their nature, technical artifacts. Whereas developers can easily comprehend JSON payloads, OpenAPI (<a href="/radar/tools/swagger">Swagger</a>) specs and <a href="/radar/tools/postman">Postman</a> demos, business stakeholders tend to respond better to demos they can interact with. The value of the product is more clearly articulated when you can see and touch it, which is why we sometimes find it worthwhile to invest in <strong>demo frontends for API-only products</strong>. When a custom graphical UI is built alongside an API product, stakeholders can see analogies to paper forms or reports that might be more familiar to them. As the interaction model and richness of the demo UI evolves, it allows them to make more informed decisions about the direction the API product should take. Working on the UI has the added benefit of increasing developers' empathy for business users. This isn't a new technique — we've been doing this successfully when necessary as long as API products have been around. However, because this technique isn't widely known, we thought it worthwhile calling attention to it.</p>
Lakehouse architecture	Trial	Poo	TRUE	<p><strong><a href="https://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf">Lakehouse architecture</a></strong> is an architectural style that combines the scalability of data lakes with the reliability and performance of data warehouses. It enables organizations to store and analyze large volumes of diverse data in a single platform as opposed to having them in separate lake and warehouse tiers, using the same familiar SQL-based tools and techniques. While the term is often associated with vendors like Databricks, open alternatives such as <a href="/radar/platforms/delta-lake">Delta Lake</a>, <a href="/radar/platforms/apache-iceberg">Apache Iceberg</a> and <a href="/radar/platforms/apache-hudi">Apache Hudi</a> are worth considering. Lakehouse architecture can complement <a href="/radar/techniques/data-mesh">data mesh</a> implementations. Autonomous data product teams can choose to leverage a Lakehouse within their data products.</p>
Verifiable credentials	Trial	Poo	FALSE	"<p>When we first included it in the Radar three years ago, <strong>verifiable credentials</strong> (VC) was an intriguing standard with some promising potential applications, but it wasn't widely known or understood outside the community of enthusiasts. This was particularly true when it came to the credential-granting institutions, such as state governments, who would be responsible for implementing the standards. Three years and one pandemic later, the demand for cryptographically secure, privacy-respecting and machine-verifiable electronic credentials has grown and, as a result, governments are starting to wake up to VC's potential. The <a href=""https://www.w3.org/TR/vc-data-model/"">W3C standard</a> puts credential holders at the center, which is similar to our experience when using physical credentials: users can put their verifiable credentials in their own digital wallets and show them to anyone at any time without the permission of the credentials' issuer. This decentralized approach also helps users to better manage and selectively disclose their own information which greatly improves data privacy protection.</p>

<p>Several of our teams have engaged in projects involving verifiable credentials technology in the past six months. Not surprisingly, the scenarios vary across countries and government departments. Our team has explored different combinations of decentralized identifiers, verifiable credentials and verifiable presentation on multiple projects. This is a developing field, and now that we've had more experience, we want to keep track of it in the Radar.</p>"
